mutation.tree.root=PiTest Mutation History
clear.button=Clear All History
search.placeholder=Search History
inspection.group.name=Pitest Unit Test Specification
inspection.display.name=Pitest Unit Test Specification Inspection
inspection.problem.descriptor=Missing or invalid unit test annotation
llm.generate.suggestions=Generate Suggestions
llm.check.prompt=Check Prompt
llm.select.file=Select Class
llm.thinking=Thinking
llm.copy.to.clipboard=Copy to Clipboard
llm.clear=Clear Chat
llm.user=User
llm.assistant=Assistant
llm.system=System
llm.error=Error
llm.dry.run.prompt=Dry Run Prompt
llm.dry.run.prompt.empty=No suggestion provided. Please check if the mutation testing result is valid.
llm.new.unit.test.suggestion=New Unit Test Suggestion
llm.prompt.system=You are a specialized code analysis assistant focused on improving unit test coverage based on mutation testing results. Your task is to first analysis the mutation result, look at the lines that have both `KILLED` and `SURVIVED` mutations; and then look at the unit tests that can execute the mutations, exam how the test `KILLED` the mutation and why some `SURVIVED`. Finally, suggest specific unit tests to handle the `SURVIVED` mutations.
llm.prompt.user=Please analyze the following mutation testing results and suggest specific unit tests:\n\n=== Source Code Under Test ===\n```\n%s\n```\n\n=== Current Test File ===\n```\n%s\n```\n\n=== Mutation Testing Statistics ===\nTotal Mutations: %d\nKilled Mutations: %d (%.1f%%)\nSurvived Mutations: %d (%.1f%%)\n\n=== Detailed Mutation Analysis ===\n%s\n\nBased on the above analysis, please provide:\n1. Specific test cases to handle survived mutations\n2. The exact assertions needed for each test case\n3. Brief explanations of why each test is necessary\nFormat your response in markdown with code blocks for the test cases.
llm.prompt.user.compact=Please analyze the following mutation testing results and suggest specific unit tests. Note: Please add the class under test's source code and test class's source code into analysis context.\n\n=== Test Information ===\nTest Class: %s\n\nClass Under Test: %s\n\n=== Mutation Testing Statistics ===\nTotal Mutations: %d\nKilled Mutations: %d (%.1f%%)\nSurvived Mutations: %d (%.1f%%)\n\n=== Detailed Mutation Analysis ===\n%s\n\nBased on the above analysis, please provide:\n1. Specific test cases to handle survived mutations\n2. The exact assertions needed for each test case\n3. Brief explanations of why each test is necessary\nFormat your response in markdown with code blocks for the test cases.
llm.error.connection=Cannot connect to Ollama server. Please check if the server is running and accessible.

# LLM Settings UI
llm.settings.connection.title=Connection Settings
llm.settings.model.title=Model Settings
llm.settings.output.title=Output Settings
llm.settings.test.title=Connection Test

llm.settings.host.label=Host:
llm.settings.port.label=Port:
llm.settings.model.label=Model:
llm.settings.maxTokens.label=Max Tokens:
llm.settings.temperature.label=Temperature:
llm.settings.timeout.label=Timeout (ms):
llm.settings.copyMarkdown.label=Copy output as Markdown

llm.settings.host.tooltip=The hostname or IP address of your Ollama server
llm.settings.port.tooltip=The port number of your Ollama server
llm.settings.model.tooltip=The name of the Ollama model to use
llm.settings.maxTokens.tooltip=Maximum number of tokens in the response
llm.settings.temperature.tooltip=Controls randomness in the response (0.0 to 1.0)
llm.settings.timeout.tooltip=Request timeout in milliseconds
llm.settings.copyMarkdown.tooltip=When enabled, copied output will be in Markdown format. When disabled, copies the rendered output.

llm.settings.test.button=Test Connection
llm.settings.help.title=Connection Help:
llm.settings.help.running=Make sure Ollama is running on your system
llm.settings.help.host=Default host is localhost (127.0.0.1)
llm.settings.help.port=Default port is 11434

# Settings Menu
settings.testcraft.title=TestCraft
settings.testcraft.description=Configure various aspects of TestCraft:
settings.testcraft.annotations=Test Annotations
settings.testcraft.annotations.description=Configure test case annotation schema and validation
settings.testcraft.asserts=Test Case Validation
settings.testcraft.asserts.description=Set up rules for validating test assertions
settings.testcraft.llm=LLM Settings
settings.testcraft.llm.description=Configure Ollama LLM integration for test suggestions

# Invalid Test Case Settings
settings.invalidTestCase.title=Test Case Validation Settings
settings.invalidTestCase.enableCheck=Enable invalid assertion check
settings.invalidTestCase.enableCheck.tooltip=When enabled, test methods will be checked for invalid assertion patterns
settings.invalidTestCase.enableCommentCheck=Enable test step comment check
settings.invalidTestCase.enableCommentCheck.tooltip=When enabled, test methods will be checked for descriptive comments
settings.invalidTestCase.assertions.title=Invalid Assertion Patterns
settings.invalidTestCase.assertions.description=Enter patterns for assertions that should be flagged as invalid (one per line):
settings.invalidTestCase.assertions.examples.title=Examples of invalid assertions that will be flagged:
settings.invalidTestCase.assertions.examples.1=• assertTrue(true) - trivial assertion
settings.invalidTestCase.assertions.examples.2=• assertEquals(1, 1) - comparing same values
settings.invalidTestCase.assertions.examples.3=• assertNotNull(new Object()) - testing newly created object
settings.invalidTestCase.assertions.examples.4=• assertEquals("success", "success") - comparing identical strings

# Tool Windows
toolwindow.mutation.title=TestCraft Mutation Test History
toolwindow.llm.title=TestCraft LLM Suggestions

# Action Text (using IntelliJ's message format)
action.RunPitestAction.text=Run Mutation Test
action.RunCaseAnnoationCheckAction.text=Run Current Method Annotation Check
action.GenerateAnnotationCommandAction.text=Generate Testcase Annotation On Method
action.CheckInvalidTestCasesAction.text=TestCraft Check Invalid Test Cases
action.UnittestHelperToolMenu.text=TestCraft Unittest Helpers
action.UnittestHelperSubMenu.text=TestCraft Unittest Helper Tools

# Annotation Settings
settings.annotation.import.title=Import Settings
settings.annotation.package.label=Annotation Package:
settings.annotation.package.tooltip=Package name for test annotation (e.g. com.example.unittest.annotation)
settings.annotation.autoImport=Auto Import Annotation Definition
settings.annotation.autoImport.tooltip=Automatically import test annotation when needed
settings.annotation.enableValidation=Enable Annotation Validation
settings.annotation.enableValidation.tooltip=Validate test annotation against the schema
settings.annotation.schema.title=Schema Configuration
settings.annotation.schema.label=JSON Schema:
settings.annotation.schema.help.title=JSON Schema Format Guide
settings.annotation.schema.help.intro=Define your test annotation schema in JSON format. The schema specifies the structure, validation rules, and default values for your test annotations.
settings.annotation.schema.help.structure.title=Schema Structure:
settings.annotation.schema.help.structure.1=fields: Array of field definitions
settings.annotation.schema.help.structure.2=Each field must have: name (string), type (STRING or STRING_LIST)
settings.annotation.schema.help.structure.3=Optional properties: required (boolean), defaultValue, validation
settings.annotation.schema.help.validation.title=Validation Rules:
settings.annotation.schema.help.validation.1=allowEmpty: boolean - Whether empty values are allowed
settings.annotation.schema.help.validation.2=validValues: string[] - List of allowed values
settings.annotation.schema.help.validation.3=allowCustomValues: boolean - Whether values outside validValues are allowed
settings.annotation.schema.help.validation.4=mode: EXACT or CONTAINS - How to match values against validValues
settings.annotation.schema.help.validation.5=minLength/maxLength: number - For STRING_LIST type only
settings.annotation.schema.help.valueProvider.title=Value Providers:
settings.annotation.schema.help.valueProvider.1=valueProvider: Optional configuration to automatically populate field values
settings.annotation.schema.help.valueProvider.2=FIRST_CREATOR_AUTHOR: Automatically sets the value to the first author who created the test
settings.annotation.schema.help.valueProvider.3=METHOD_NAME_BASED: Generates a value based on the test method name
settings.annotation.schema.help.example.title=Example Schema:
settings.annotation.schema.help.notes.title=Important Notes:
settings.annotation.schema.help.notes.1=STRING fields must contain string values
settings.annotation.schema.help.notes.2=STRING_LIST fields must contain arrays of strings
settings.annotation.schema.help.notes.3=Required fields cannot be null or missing
settings.annotation.schema.help.notes.4=Default values are used when a field is missing or null
settings.annotation.schema.help.notes.5=Validation rules are applied after type checking

llm.error.no.mutations=No mutations found in the current file. Or there is no KILLED and SURVIVED mutations.

# Target Class Input Dialog
dialog.target.class.message=Please enter the name of the class that you want to test
dialog.target.class.title=Enter target class

# Error Messages
error.pitest.dependencies=Cannot find pitest dependencies
error.pitest.title=Error
error.pitest.general.title=Pitest Error

# Test Annotation Messages
test.annotation.details.title=Test Annotation Details
test.file.action.title=Test File Action
test.annotation.generation.title=Annotation Generation Action
test.methods.not.found.title=No Test Methods Found
test.methods.no.annotation.title=No Test Methods Can Add Annotation
test.annotation.exists.title=Annotation Already Exists

# Pitest Run Messages
pitest.run.canceled=Pitest run was canceled
pitest.run.canceled.title=Canceled
pitest.run.error=Error executing Pitest command: %
pitest.view.report=View HTML Report

# Chat
chat.send.button=Send

# Invalid Test Cases Result
invalid.test.cases.result.initial.message=No invalid test cases found. Right click on a project directory to scan for invalid test cases.
invalid.test.cases.result.found.invalid.test.cases=Found %d invalid test cases:
invalid.test.cases.result.no.invalid.test.cases.found=No invalid test cases found.Right click on a project directory to scan for invalid test cases.

# Tool Window
toolwindow.llm.suggestion.tab.name=LLM Mutation Suggestions
toolwindow.mutation.tab.name=Mutation History
toolwindow.invalid.testcases.tab.name=Invalid Test Cases

# Test Scan Messages
testscan.scanning_test_classes=Scanning test classes...
testscan.checking_test_cases=Checking test cases...
testscan.no_invalid_test_cases_found=No invalid test cases found.
testscan.found_invalid_test_cases=Found {0} invalid test cases:
testscan.test_case_validation_results=Test Case Validation Results